
\chapter{The Trigger System on~\atlas}
\label{SECTION-TRIGGERS}

Interaction rates in the ATLAS detector are staggering. Since we can not store information on every interaction we must filter it through the ATLAS trigger system and keep only events which have the prospects to contain interesting processes. There are three terms worth defining here. The trigger is the decision making process used by \atlas~ to distinguish interesting events from non-interesting ones, Data acquisition refers to the system that delivers and stores wanted events and variables, and data preparation which prepares saved data for analysis. The trigger is separated into three levels that start with hardware on the detector and get more computationally intensive as they progress. They are Level1, Level2, and Event Filter. A trigger chain is a set of trigger settings that can be designed around hardware responses, reconstructed objects, and reconstructed events. There are approximately 700 different trigger chains. With so many types of events to be seen we must limit the rate of any given trigger chain due to bandwidth considerations. With this in mind every proposed trigger chain is evaluated for efficiency, purity, overall rate, overlap rate with other trigger chains, response to pile up, response to increased luminosity, and its usability in many analysis or at least one well motivated analysis. 

This system was designed with four main principles in mind. 

\begin{enumerate}
\item{Factorization and partitioning}
\item{Minimization of data movement}
\item{Uniformity and minimization of required developments}
\item{Staging of data volumes and rates}
\end{enumerate}

Partitioning of the trigger into relevant components is important so that various subsystems can run independently and concurrently. The capacity to run with only a fraction of the trigger chains was deemed important to be able to debug existing trigger chains as well as be able to commission new trigger chains. Minimizing data movement is key to keeping high rates of throughput with low latency. Uniformity allows adoption of common hardware that can be purchased more cheaply and replaced more easily. Staging the trigger into three levels was  done in part to keep the trigger adaptable so as the physics environment changed the trigger could be adapted or expanded. 

\LARGEFIG{Zee}{A $Z$-boson decaying to an electron positron pair.}{FIGURE-Zee}

If problems arise with a trigger chain they can be dealt with in several ways. The first tool of evaluation of many triggers is the tag and probe method. In this method two objects can be selected from an event, one of which (known as the tag) will be given a tight requirement to ensure purity of a particular sample while the other (known as the probe) is taken to be tested on. An example is a $Z$-boson going to two electrons with one electron being a tag while the other is a probe to test the efficiency of the single electron trigger chain. The Feynman diagram can be seen in Figure~\ref{FIGURE-Zee}. The probe is then classified into three groups; passing the tag criteria, passing the probe criteria, or failing the probe criteria. Once we know how the electron failed we can take steps to correct the inefficiency. If the trigger rate is too high we will not be able to record events that pass the trigger. In this case it is common to use prescales. Prescales reject a given percentage of events that would otherwise pass a trigger chain in order to make bandwidth for other trigger chains. Their use is often motivated by the generality or usefulness of the trigger chain and political will to keep events from that trigger chain.


\section{Level 1 Trigger}
\label{SECTION-TRIGGERS-L1}

The Level1(L1) trigger is hardware based and looks at each segment of each subdetector individually to determine if the event should be passed. The L1 trigger is composed of several parts. L1Calo looks at the level of calorimeter deposits and their multiplicity while L1Muon looks at the muon systems in the same way. the L1 trigger also has front end analog-digital processing (the hookup to the actual detector), the L1 buffer to store information for long enough to accommodate L1 latency, the derandomizing buffer where L1Accept signals are stored to be sent to the L2 trigger, buses for transmitting the front end data stream to the back end electronics, the Central Trigger Processor(CTP) which is the brains of the trigger system and makes the decisions on each event based on a premade trigger menu, the Trigger Timing Control(TTC) which is responsible for ensuring that all individual detector readouts are synchronized and properly labeled by bunch crossing and interaction point, and the Region of Interest Builder(RoIB) which prepares passed events for L2. 

There are four main environmental considerations that influence the design of the front end readout electronics; radiation effects, magnetic fields, space around the detector for access, and the location of the service caverns housing the back end electronics. Radiation is a concern because, for example, read out electronics can be falsely triggered by radiation energy. Magnetic fields dictate the composition of components in the electronics especially in power supplies. Access is problematic in areas where there is a lot of detector material with little room for read out electronics such as the inner detector. The service caverns can house electronics without worries about radiation, and thus can house electronics that would otherwise be unavailable in the cavern. The types of links are then defined by the type of data being transmitted (analog or digital) as well as the speed it is transmitted through the length of the links which ranges from 50 to 150 meters.~\cite{Green:1221848}~\cite{DETECTORS}

The L1 trigger takes the potential data rate from 20 MHz to 75 kHz in a latency of less than 2.5 $\mu$s including propagation delays the cables to get the information to the trigger logic circuit~\cite{Green:1221848}. Latency is the time delay from detector response to the actual trigger decision. Because of the need for such low latency L1 considers information on calorimetry and muon systems but not information on tracking because the reconstruction algorithms required are too slow.~\cite{DETECTORS}


\section{High Level Trigger}
\label{SECTION-TRIGGERS-HLT}

The HLT is the name given to the portion of the trigger that is largely software based. It is designed to run on common computer hardware and computing cores from L2 and EF are often interchangeable (and in fact they are interchanged regularly). 

The Level2(L2) trigger is software based and looks at Regions of Interest(RoI) passed to it by L1. The use of these RoIs in software make the L2 trigger common hardware, allowing for 500 identical PCs to be used. These RoIs give more information to make decisions and are given more time to make those decisions in. The L2 trigger takes the data rate from 75 kHz to 6.5 kHz with 75 ms to make a decision on each event. In this time they must take 1600 parallel fragments, held in 150 readout systems. These fragments must be merged into a single event which is a computationally slow process. 

The Event Filter(EF) is the most comprehensive trigger and looks at the entire event as reconstructed by the event builder to decide if an event will get saved to the ATLAS tier0 data storage center. The EF is comprised of 1800 PCs that can be interchanged with the L2 PCs. The EF goes from an input data rate of 6.5 kHz to around 1 kHz output with 4 seconds to make a decision on each event.


\section{Trigger Chains}
\label{SECTION-TRIG-CHAIN}
 A look at the final state of interest will inform what trigger chains are worth looking into. For \tz~ the final state of interest in Figure~\ref{FIGURE-tZ} has the $Z$-boson decaying into two leptons; the top-quark decaying to one lepton, one b-jet, and \MET; and one additional forward jet. This creates a situation where many different trigger chains can be utilized effectively. Despite many triggers being used the requirements by the top group and the cuts on this analysis limit the practical list down to a few lepton triggers. The TOPQ2 samples have a requirement that there either be $>=$ 2 leptons with pT $>$ 15 GeV and $|eta|$ $<$ 2.5 OR $>=$ 2 leptons pT $>$ 10 GeV and $>=$ 1 with pT $>$ 20 GeV and $|eta| <$ 2.5. This requirement along with the lepton trigger matching requirement described in Chapter~\ref{SECTION-OBJ} and the electron or muon selection described in Chapter~\ref{SECTION-ANALYSIS} mean that the electron and muon trigger chains are the most relevant. The diversity of objects in \tz~ means that these triggers could have been relevant but they are filtered out at later levels of analysis as described in the offline reconstruction section in Chapter~\ref{SECTION-OBJ}. 


\subsection{Single Muon}
\label{SECTION-TRIGGERS-1mu}

Another relevant trigger that applies to this analysis is the single muon trigger. This begins with the muon interacting with the various components of the detector as described in Chapter~\ref{SECTION-EXPERIMENT}. The most useful interaction for muon triggering purposes is the Resistive Plate Chamber(RPC) hits. If there are coincident hits in multiple layers of the RPC a muon candidate is flagged and passed to the HLT for the Region of Interest Builder(RoIB) can create a Region of Interest(RoI). The HLT then uses this RoI to make a few requirements on the quality of possible muon candidates. One of the requirements of the HLT is that hits in the RPC, TGC, MDT, and ID line up in $\eta-\phi$ for a muon candidate. Another is that the muons be isolated from hadronic activity to improve the selection of muons originating from $W$-boson or $Z$-boson decays while mitigating muons from pion or heavy quark decays which are put into B-physics streams. Cosmic muons are also rejected by tracing back where the muon hits will not point back to the interaction point. Once those requirements have been met further checks are performed to ensure the quality of muons that are wholly reconstructed by every layer of the detector and to verify that the requirements were accurately met. The event is then stored with information on the various triggers passed or failed, and objects are reconstructed offline in the top derivation framework to be analyzed. ~\cite{TrigProposal}

\subsection{Single Electron}
\label{SECTION-TRIGGERS-1e}

One of the most relevant triggers that applies to this analysis is the single electron trigger. This begins with the electron interacting with the various components of the detector as described in Chapter~\ref{SECTION-EXPERIMENT}. At L1 energy depositions in the electromagnetic and hadronic calorimeters are considered, and a Region of Interest(RoI) is build around high depositions. This RoI cluster must be high enough energy as well as being isolated from other activity in the electromagnetic calorimeter and be isolated  activity in the hadronic calorimeter. At this point an EM object is passed to the HLT. Note that the object passed is not an electron yet, because photons exhibit very similar behavior with its interactions in the electromagnetic calorimeter. Once an RoI has been passed to the HLT we can take ID interactions into account. Energy clusters in the electromagnetic calorimeter can be matched in $\eta-\phi$ and its energy can be compared to the momentum measured by the inner detector tracks. Isolation requirements in the electromagnetic calorimeter and hadronic calorimeter can be re-assessed after corrections can be applied, and isolation on tracks can be applied to ensure the entire energy deposit came from one primary vertex. Once these requirements are met the event is stored with information on the various triggers passed or failed and the electron (and other objects in the event) are reconstructed offline in the top derivation framework to be analyzed. ~\cite{TrigProposal}

Other multilepton triggers can also contribute which work on similar principles as the single electron and single muon triggers. These trigger chains have varied thresholds to accept pairs of objects that are individually more loosely defined (both in energy/momentum thresholds as well as isolation) compared to their single counterparts.~\cite{ATLASTDAQ}
