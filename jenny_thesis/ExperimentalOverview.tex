\chapter{ATLAS and the LHC}
In order to study the single-top $t$-channel cross-section, we must first collect information from these rare events.  The top quark is very massive and requires a large amount of energy to produce events containing it.  To do this, we generate high energy particles in beams and collide them together in an underground ring.  Here, we can collect most of the information about the particle tracks and energies and also produce a large number of these collisions.  This last point is crucial for low cross-section processes like the signal in this analysis.

\section{The Large Hadron Collider, a Short Overview}\label{sec:LHC} 
The Large Hadron Collider~\cite{LHCoverview}, or LHC, is the particle collider in question, a proton-proton collider located on the border of Switzerland and France, near Geneva, Switzerland.  It is 26.7 km in circumference, or 5.3 miles in diameter, and the beams collide with a center-of-mass energy of 7 TeV during normal data taking.  This is half of the design center-of-mass energy (14 TeV) and is what is used for the data in this analysis.  The first 7 TeV collisions occurred in March of 2010, and this document considers data taken in the first half of 2011.

The LHC is the main ring, which reuses the former LEP tunnel, and there are several other rings that boost the beam up to its injection energy of 450 GeV.  First, though there is the proton source, where hydrogen gas is separated into protons and electrons via a magnetic field.  The protons are then sent into the first part of the accelerator complex, a linear accelerator called the LINAC2.  It is also possible to collide lead in the LHC and in this case a different source is used, but for our purposes we will focus on the standard proton-proton collisions.  After reaching the LINAC2, the protons go through circular accelerators to boost the beam energy, the Proton Synchrotron Booster (PSB), Proton Synchrotron (PS), and Super Proton Synchrotron (SPS) systems, before being injected into the LHC.

The protons are formed into bunches and trains of bunches before they are collided, incidentally allowing some spacing for one collision's particles to decay or leave the detector before the next set of particles collide.  Within one bunch there are about 100 billion protons, not all of which actually collide or collide to produce interesting events.  Each bunch is spaced apart by 50 ns and the number of bunches in the ring has been increasing steadily as data taking has progressed, up to about 1000.  
%shouldn't bunch train spacing get smaller with more bunches...?
%bunch train spacing?  Spacing between trains depends on the number of bunches in the train.  About 225ns for 36 bunches, about 1000ns for 144 bunches used in June (need source).  http://blog.vixra.org/2011/05/29/new-luminosity-record-for-lhc/  MC has 225ns spacing.
%Because the ring is 26.7 km around, this means each bunch is spaced apart by only about XXX m near the end of the data set we will consider in this analysis.

Of course, the reason these bunches are put so close together and contain so many particles is related to getting enough data to find the single-top t-channel production we are looking for.  The instantaneous luminosity~\cite{Luminosityoverview}, which reflects how many events are produced, is determined by various accelerator settings:

\begin{equation} 
L = \frac{f_{r}n_{1}n_{2}n_{b}\gamma_{r}F(\theta,\sigma)}{4\pi \epsilon_{n}\beta^{*}}
\end{equation}

Here $f_{r}$ is the frequency the protons go around the main LHC ring (approximately the speed of light, c,  divided by 27 km), $n_{1}$ and $n_{2}$ are the number of protons per bunch, $n_{b}$ is the number of bunches in each beam, $\epsilon_{n}$ is the normalized emittance (related to the deviation of particles from the ideal beam and thus also beam lifetime), and $\beta^{*}$ is related to the beam focus at the interaction point.  The combination $\epsilon_{n}\beta^{*}$ is the overall beam size at the collision point.  Here, the $\beta^{*}$ is 1.5 m and the emittances are on the order of $\mu m$, $4 \times 10^{-6}~m$~\cite{LHCdetail}.  The $\gamma_{r}$ is the relativistic $\gamma$, which is just the beam energy (3.5 TeV per beam) divided by the proton mass (about 1 $GeV/c^2$), about $3.5\times 10^{3}$.  Finally, the $F(\theta,\sigma)$ is a geometrical luminosity reduction factor 
% involving the Piwinki parameter, 
related to the beam size and crossing angle, and is about 0.84~\cite{LHC2}.  The peak instantaneous luminosity varies day by day (it will fall off as a data collection run goes on), but is approximately $1 \times 10^{33}cm^{-2}s^{-1}$ for the time period in question.  Following the equation, and putting in approximate values, we can get a similar number:
\begin{equation} 
L = \frac{10^{4}s^{-1} \cdot 10^{11}\cdot 10^{11}\cdot 10^{3}\cdot 3.5\times10^{3}\cdot 0.84}{4 \pi \cdot 4\times 10^{-4} cm \cdot 1.5\times 10^{2} cm} = 4 \times 10^{32}cm^{-2}s^{-1}
\end{equation}

With such tight beam focus and so many particles, it is possible to have more than one collision per bunch crossing.  On average, for the data we consider here, there are about six interactions per crossing.  The impact of the change in $\beta^{*}$ for the data used for this analysis and the following data can be seen in Figure~\ref{fig:betastar}.  The decrease in $\beta^{*}$ approximately doubled the number of events per crossing in later data sets.  The lower number of interactions per crossing is an advantage of the data set used in this document.  Most of these extra interactions are not interesting, but it is possible that the events could mix in a way that confuses the event identification.  Studies are done to check that the analysis is not biased by these ``pileup'' effects.

\begin{figure}[!htpb]
  \centering
    \includegraphics[width=0.75\textwidth]{figures/detector/interactionspercrossing2011.eps}
    \label{fig:betastar} 
\caption{Average number of interactions per crossing for the 2011 ATLAS data set for different values of $\beta^{*}$ used by the LHC.  The $\beta^{*} = 1.5~m$ data set was used for the analysis in this document~\cite{betastar}. ATLAS Experiment \copyright 2011 CERN.}
\end{figure}

What is typically quoted is not the instantaneous luminosity but the integrated luminosity (luminosity for a given period of time).  This is usually expressed in units like $pb^{-1}$ (a barn is $10^{-28} m^{2}$), which means this can be easily multiplied by a cross-section in $pb$ to determine the number of events expected, as seen in Section~\ref{sec:ExpectedCrosssections}.  For this analysis, we are considering 1035.27 $pb^{-1}$, or 1.04 $fb^{-1}$.

However, even after all of these events are produced, nothing can be measured without a detector to collect the relevant information about the collision.  The information provided is not a snapshot of the interaction we are interested in like the Feynman diagrams in Section~\ref{sec:Feynman}, but rather the final, relatively stable particles that come out of it which actually reach the detector.  There are four different detectors located around the LHC ring at different points where the beams cross to produce collisions, and this analysis uses data from the ATLAS detector.

\section{The ATLAS Detector}
The ATLAS (A Toroidal LHC ApparatuS) detector~\cite{ATLASoverview}, shown in Figure~\ref{fig:ATLAS} is a multipurpose detector designed to detect many different processes.  It is a very large detector, the largest constructed by volume, and is about 25 meters (or 82 feet) high.  It consists of several different detector components designed to detect the various particles that travel through it.  In general, these include b-quarks, lighter quarks, electrons, and muons (as well as photons, but these don't appear in our final state).  The quarks hadronize to form ``jets'' of particles which are actually detected in the detector.
\begin{figure}[!htpb]
  \centering
    \includegraphics[width=1.00\textwidth]{figures/detector/ATLAS_cutaway.eps}
    \label{fig:ATLAS} 
\caption{Cut away view of the ATLAS detector~\cite{ATLASoverview}, ATLAS Experiment \copyright 2008 CERN.}
\end{figure}

\subsection{Detector Variables and Geometry}
There is certain information that is determined in the detector itself: energy, timing and particle track information.  The layout of the detector is with the z-axis along the beamline.  The y-axis points up vertically from the detector and the x-axis is the remaining direction, pointing towards the center of the LHC ring.  The $\phi$ direction is the angle measured in the x and y plane, starting from the positive x axis, and the $\theta$ direction is measured in the y and z plane, starting from the positive z axis.  Figure~\ref{fig:ATLASGEO} shows the orientation of the axes with respect to the surrounding area.

\begin{figure}[!htpb]
  \centering
    \includegraphics[width=1.00\textwidth]{figures/detector/LHCexperiment_axis1.eps}
    \label{fig:ATLASGEO} 
\caption{View of ATLAS, the LHC and other experiments~\cite{ATLASaxes}, ATLAS Experiment \copyright 1999 CERN.  The black axis lines are added for reference.}
\end{figure}

The $\theta$ angle is generally not used as such but transformed into a quantity called pseudo-rapidity ($\eta$):

\begin{equation} \eta = -ln(tan(\theta/2)) \end{equation}

%rapidity vs pseudo rapidity?
This quantity is 0 if the particle heads out of the interaction perpendicular to the beam ($\theta = 90^{\circ}$) and is about 4.5 close to the beamline ($\theta= 1^{\circ}$), at the limit of the detector.  Figure~\ref{fig:EtaTheta} shows absolute values of $\eta$ for various values of $\theta$.

\begin{figure}[!htpb]
  \centering
    \includegraphics[width=0.60\textwidth]{figures/detector/EtaTheta.eps}%was 0.45 for size
    \label{fig:EtaTheta} 
\caption{Graphic showing absolute values of $\eta$ for various values of $\theta$.}
\end{figure}

It is also common to use the quantity $\Delta R$ as a measure of separation.  We define this as:
\begin{equation} \Delta R^2 = \Delta \eta^2 + \Delta \phi^2 \end{equation}
Additionally, the term transverse in this document (denoted by a subscript T) means the combination of the X and Y directions, which is perpendicular to the beam direction along the z axis.  For instance, \pt is the transverse particle momenta, $\rm \sqrt{p_{X}^2 + p_{Y}^2}$.


\subsection{The Inner Detector}
%give pixel physical size? 
The inner detector has the finest resolution of the various sub-detectors.  The fine resolution is particularly important for identifying and reconstructing hadronized b-quarks, or b-jets, which will be discussed in more detail in Section~\ref{sec:Btag}.  The primary purpose of the inner detector is tracking.  This is also the closest detector to the beam pipe in the central region and covers a region of $|\eta| < 2.5$.

There are three major sections: Pixel, SemiConductor Tracker (SCT), and Transition Radiation Tracker (TRT).  The Pixel is the innermost section and has an initial layer called the B-layer.  The closeness of this layer to the interaction is limited by the beam pipe itself, which is about 6 cm in diameter.  This section of the detector is composed of small squares of silicon (pixels) and offers very good postitional resolution, 10 $\mu m$ in R-$\phi$ space and 115 $\mu m$ in Z.  As charged particles hit the silicon, ionization electrons flow to anodes and a signal is created.  There are three pixel layers circling the barrel region and an additional three layers on each side.  The next section is the SCT.  It is very similar to the pixel section but has microstrips of silicon about 6 cm long rather than pixels.  It has four layers of back-to-back strips giving a possible 8 hits per track.  The resolution is still good although not quite as precise as the pixel region particularly in the Z direction (17 $\mu m$ in R-$\phi$ space and 580 $\mu m$ in Z).

Finally there is the TRT which is basically a two part detector.  It consists of ``straw tubes'' which are tubes filled with Xenon gas and a wire down the middle. Each tube is 4 mm in diameter and 37 cm long in the endcap region or 144 cm long in the barrel region.   Around these tubes are various materials with different dielectric constants.  When particles, especially very high energy, low-mass particles like electrons pass through these different materials, transition radiation is emitted.  These photons hit the Xenon-filled tubes and create ions which, because of a potential different between the tube and the wire in the center, drift towards the wire and cause a signal.  This is particularly useful in helping with electron identification, especially for $|\eta| < 2.0$.  The position resolution in this section isn't as good as the pixel or SCT detectors, but there are still about 300,000 straws over a large area, and particles will have more ``hits'' in the TRT straws than the previous detector sections, assisting with particle track reconstruction.  The TRT only provides R-$\phi$ information and can resolve to 130 $\mu m$ per straw.  However, each track has approximately 36 hits in this region, compared to 3 or 8 in the other two inner detector regions.

\subsection{The EM Calorimeter}
%kapton electrodes?
The electro-magnetic (EM) calorimeter is particularly intended to pick out the tracks and energy of electrons and photons, which tend to stop in this region.  It is composed of layers of lead with steel and liquid argon (LAr), starting with an initial LAr layer called the presampler which gathers information about showers that may have occurred in previous detector material.  Through the rest of the calorimeter, the electrons will interact with layers of lead.  There are three major layers, and most electrons of high enough energy for physics analyses like this one are deposited in the central layer.  This layer has 0.025x0.025 resolution in $\eta - \phi$ space.  The first layer helps with rejection of photons or pions and the last layer helps collect energy from very energetic electrons.  More energetic electrons will make showers in more of the lead layers.  The showers themselves are detected via creation of ions in the LAr.  Photons are also detected in this region and are distinguished from electrons by the lack of a track in the inner detector.  There are two levels of coverage in this detector. The central region, $|\eta| < 1.5$ contains slightly more layers and better resolution than the two-wheel endcap region, $1.4 < |\eta| < 3.2$.  The resolution is worst in the forward region of this detector, $2.5 < |\eta| < 3.2$, and this analysis will not consider electrons from this region.

It should be noted that there is one particular region of the detector between the barrel and endcap in the EM calorimeter, $1.37 < | \eta | < 1.52$, where there is excessive extra material between the inner detector and the EM calorimeter~\cite{Electron}.  This makes it difficult to properly reconstruct the energy of electrons that are detected, and of course they may deposit most of their energy in this region and never make it into the rest of the detector at all.  This is sometimes referred to as the "crack" region and electrons from this region are not considered in the analysis.

\subsection{The Hadronic and Forward Calorimeters}
The hadronic calorimeter is where the hadronic showers from hadronizing quarks tend to reach and eventually stop.  Here we complete the track and energy information for jets, the shower of particles from a hadronizing quark.  The portion of the jets that hit the calorimeter are actually composed of various light particles, commonly including particles such as pions and kaons (which have masses of about 140 MeV and 500 MeV, respectively). This part of the detector is special because it contains not only a central and barrel region, but also a forward region which is next to the beam pipe (as is the inner detector).  Each of the regions have some overlap with each other to avoid lining up too many detector transition regions with each other (where resolution extra material is present and resolution is not as good).  Extra material can cause extra interactions that may not be well modeled and particles could be missed, so it is important to minimize this.

The central region ($|\eta| < 1.7$) contains scintillating tiles and steel, and is known as the tile calorimeter.  The hadrons interact with the layers of steel and the showering particles create photons when they hit the scintillating tiles.  These photons are then collected by photomultipliers, which turn the photons into an electrical signal.  The barrel region ($1.5 < |\eta| < 3.2$) contains the hadronic end-cap calorimeters (HEC), which uses LAr and is essentially an extension of the EM calorimeter but with copper plates.  There are three layers in the barrel and four in the endcap, with a resolution of about 0.1x0.1 in $\eta - \phi$ space for $| \eta | < 2.5$ and 0.2x0.2 otherwise in the endcap region.

The forward region ($3.1 < |\eta| < 4.9$) has special forward calorimeters right next to the beam pipe and thus has a different configuration to handle the larger amounts of radiation.  Here, copper has tube-shaped holes formed in it with each hole containing a tungsten rod and LAr between the two.  The particles shower in the copper and the ions form in the LAr and travel towards the rod.  This region is especially important for the $t$-channel single-top searches as an energetic forward jet is a distinguishing characteristic between it and its backgrounds.

\subsection{The Muon Spectrometer}
%http://arxiv.org/abs/1101.3276
%Muon systems at the LHC are described in detail in Ref. [6]. The muon differs
%from the electron only by its mass, which is around a factor 200 larger. As a consequence,
%the critical energy Ec (the energy for which in a given material the rates
%of energy loss through ionization and bremsstrahlung are equal) is much larger for
%muons: it is around 400 GeV for muons on copper, while for electrons on copper2
%it is only around 20MeV. As a consequence, muons do in general not produce
%electromagnetic showers and can thus be identified easily by their presence in the
%outermost detectors, as all other charged particles are absorbed in the calorimeter system.
%
%try to convert some resolution planes to others somehow?
Finally there is the muon system, primarily intended to detect muons, which tend to travel farther through the detector than other particles (except neutrinos, which interact so weakly that it is difficult to detect them).  This is related to the mass of the muon, which is about 106 MeV (much larger than the electron, at 0.5 MeV), and its decay time, which is much longer than the particles like pions and kaons in jets.  The longer decay time allows it to reach the outer regions of the detector ($c\tau$ is 659 m) and its larger mass prevents it from showering too much earlier in the detector.  Thus, we can have a special detector for muons, in the outermost portion of the detector, to determine information about the direction and momenta of the muons.  

There are four major components of the muon system.  Two components are dedicated to detecting the muon track and the other two are dedicated to reporting the presence of a muon (triggering) and giving additional position information.  In each case, one component is in the barrel region and the other in the endcap region.  The Monitored Drift Tubes (MDT) are primarily responsible for track determination over the full $|\eta| < 2.7$ region, except for the inner section of the muon detector forward region ($2.0 < |\eta| < 2.7$), where Cathode Strip Chambers (CSC) are used.  The general principle is similar in both cases.  There is a gas filling drift tubes or between plates, and a charged particle creates ions which drift towards a wire.  The resolution of the MDT is about 35 $\mu$m in the Z direction, while the CSC has a resolution of about 40$\mu$m in the plane orthogonal to $\phi$ and 5 mm in the $phi$ (non-bending) direction.  The triggering portions are the Resistive Plate Chambers (RPC) and Thin Gap Chambers (TGC) in the central ($|\eta| < 1.05$) and endcap ($1.05 < |\eta| < 2.4$) regions, respectively.  The first is composed of sets of plates (no wires) that the ionized particles travel between.  The second contains many wires between plates, like the CSC, but the wires are arranged differently to favor a faster response time.  These extra triggering systems are needed because the response time of the main systems is too long to allow triggering of a high \pt~ muon associated with some events, and also to provide information about the muon track in an additional ($\phi$) direction.  The RPC has a resolution of 10 mm in both the Z and $\phi$ directions while the TGC has a resolution of 2 to 6 mm in Z and 3 to 7 mm in $\phi$.

\subsection{Magnets}
It should be mentioned that one of the primary methods of measuring the momenta of charged particles is by measuring the curvature of their tracks in a magnetic field.  Magentic fields also help to distinguish charged and neutral particles (whose tracks have no curvature due to a magnetic field), aiding in particle identification.  Magnetic fields are created by two different sets of magnets in the ATLAS detector.  The first set is a 2 Tesla solenoid magnet system located between the inner detector and the EM calorimeter which provides a magnetic field for the inner detector.  In addition to providing a strong field the magnent coil and related structure must not be too thick or dense, as the particles are intended to pass through this magnet layer relatively unimpeded.  The second set consists of large toroid magnets (about 0.5 to 1 T within the muon detector) surrounding the muon system, in both the barrel and endcap regions. The tendency of a particle to curve in a magnetic field indicates that it is charged, but the degree of curvature also gives information about the momentum of the particle.  This can be seen from the equating the Lorentz and Centripetal force equations, giving (assuming non-relativistic conditions for the moment):
\begin{equation} F = Bqv = mv^2 /r \rightarrow mv = p = qBr \rightarrow p \propto r\end{equation}
where B is the magnetic field, q is the particle charge, v is particle velocity, r is the radius of curvature and p is the momentum.  From this we can see that particles with more momentum have a larger radius of curvature, meaning that the tracks will curve less (be straighter) in the detector.  Particles that are not charged will not curve due to the magnetic field.  Thus, these magnets are essential for particle identification and measurements.

\subsection{The Trigger and Data Collection}
%talk about deadtime?  detector performance ~95%?
%How large are the ROIs?
%which triggers in data streams
Finally, there is the trigger and data collection system (DAQ)~\cite{Trigger2010}.  Although not strictly part of the ATLAS detector itself, per se, this system is essential to data analyses.  The LHC produces collisions at such a high rate that it is impossible to store all of the collected data for analysis.  Most of the data, however, are glancing or low energy collisions that are not the events we are looking for in studies of processes such as single-top.  It is possible to reject many of these events immediately, using hardware triggers.  There are then two other trigger levels which spend increasing amounts of time determining if an event is worth saving or not before the data are finally recorded for use in analyses.

The three different trigger levels are called level 1 (L1), level 2 (L2) and event filter (EF).  At each level, more information is considered to determine if an event should be kept or rejected.  This is important as computer storage space would rapidly run out if all events were kept.  Most events are ``common'' events involving low energy jets.  We want to be sure that we collect enough of the less common high energy events (like the single-top events we are looking for) so we reject many of these less interesting events.

The L1 trigger is hardware only and rejects events very quickly (less than 2 $\mu s$ per event) and in large number, with a maximum rate of 75 kHz~\cite{Trigger2010, Electron} although in practice the rate may be half this value.  The other two triggers are software based.  The L1 trigger essentially just looks for high transverse energy objects in the event, but the L2 trigger considers the regions of interest (RoIs) containing these objects and can consider full detector information in these regions.  The rate after the L2 decision is about 3 kHz and it takes about 50 ms per event to make a decision to keep or reject the event at this level.  Finally the EF is the last level which looks at the whole detector and uses standard analysis reconstruction software to find the event information and make a decision.  After this stage, the event is permanently stored and disseminated to analysers.  The overall event rate at this level is about 200 to 600 Hz, much smaller than before.  It takes longer to determine whether to keep events at this level, about 4 CPU seconds per event by design (as low as 0.4 CPU seconds per event during data taking), but this is still quite fast.

There are many different types of triggers.  In this analysis, we use single lepton triggers, corresponding to the single leptons expected in the t-channel single-top final state.  When the data are processed, a low threshold trigger is initially applied, and higher threshold triggers are applied later at the analysis level.  This application of the low threshold triggers divides the data into different analysis streams.  In this document we use the Muon and Egamma (electron) streams for the main analysis.  There is also another main physics stream, the JetTauEtMiss stream, which is used in this analysis for the multijet background estimate.

\subsection{Data Quality}\label{sec:dataquality}
In some cases the detector may have a component temporarily fail or go offline, and it may not be possible to reconstruct certain particles well.  In this case, events taken during these times are rejected due to data quality issues.  This rejection is done ``offline'', meaning it is performed after the initial low threshold triggers are applied, and removes data events from the analysis by applying a ``good runs list'' (GRL) selection as the first selection on the data sample.  This is because some analyses do not use the full detector, so even if some of the data for a muon analysis for instance are not collected correctly because of technical problems with the muon spectrometer, an analysis only using the inner detector information can still use the data.  On the other hand, an analysis such as this one, which uses nearly the full detector range, would not be able to use such data.

One exception to this GRL selection is the so-called ``LAr hole'' issue, which was a problem with the front end electronics for the LAr calorimeter that created a ``hole'' in the detector data collection.  This problem persisted for a few months before being fixed and was present for all but the first 165 $pb^-1$ of the data set used in this analysis, meaning about 85\% of the data has the potential to be affected.  In this case an additional event selection is applied to the data to account for this issue, removing only events where the particle reconstruction is affected by this hole (rather than removing all of the events, which would have been the standard GRL selection procedure for an analysis like this one).  In the end, only about 10\% of data events are actually removed from the analysis due to this issue.
